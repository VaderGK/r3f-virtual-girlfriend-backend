import { exec } from "child_process";
import cors from "cors";
import dotenv from "dotenv";
import fetch from "node-fetch";
import express from "express";
import { promises as fs } from "fs";
import OpenAI from "openai";
dotenv.config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || "-", 
});

const elevenLabsApiKey = process.env.ELEVEN_LABS_API_KEY;
const voiceID = "EXAVITQu4vr4xnSDxMaL"; // Sprawd≈∫, czy ten g≈Ços istnieje

const app = express();
app.use(express.json());
app.use(cors());
const PORT = process.env.PORT || 8000;

/**
 * ‚úÖ Sprawdzanie, czy `FFmpeg` i `Rhubarb` sƒÖ dostƒôpne
 */
function checkDependencies() {
    exec("ffmpeg -version", (error, stdout) => {
        if (error) {
            console.error("üö® FFmpeg NIE jest zainstalowany!");
        } else {
            console.log("‚úÖ FFmpeg dzia≈Ça:\n", stdout);
        }
    });

    exec("rhubarb --version", (error, stdout) => {
        if (error) {
            console.error("üö® Rhubarb NIE jest zainstalowany! Pobieranie...");
            exec("curl -L -o /usr/local/bin/rhubarb https://github.com/DanielSWolf/rhubarb-lip-sync/releases/latest/download/rhubarb-linux && chmod +x /usr/local/bin/rhubarb", (installError) => {
                if (installError) {
                    console.error("‚ùå Nie uda≈Ço siƒô pobraƒá Rhubarb!", installError);
                } else {
                    console.log("‚úÖ Rhubarb zosta≈Ç pobrany!");
                }
            });
        } else {
            console.log("‚úÖ Rhubarb dzia≈Ça:\n", stdout);
        }
    });
}

checkDependencies();

app.get("/", (req, res) => {
  res.send("Hello World!");
});

app.get("/api/status", (req, res) => {
  res.json({ status: "ok", message: "Backend dzia≈Ça poprawnie!" });
});

/**
 * ‚úÖ Pobieranie dostƒôpnych g≈Ços√≥w z ElevenLabs
 */
app.get("/voices", async (req, res) => {
  try {
    const response = await fetch("https://api.elevenlabs.io/v1/voices", {
      headers: { "xi-api-key": elevenLabsApiKey },
    });
    const data = await response.json();
    res.send(data.voices);
  } catch (error) {
    console.error("‚ùå B≈ÇƒÖd pobierania g≈Ços√≥w:", error);
    res.status(500).json({ error: "B≈ÇƒÖd pobierania g≈Ços√≥w ElevenLabs." });
  }
});

/**
 * ‚úÖ Wykonywanie komend terminalowych
 */
const execCommand = (command) => {
  return new Promise((resolve, reject) => {
    exec(command, (error, stdout, stderr) => {
      if (error) {
        console.error("‚ùå B≈ÇƒÖd wykonania komendy:", command, error);
        reject(error);
      } else {
        resolve(stdout);
      }
    });
  });
};

/**
 * ‚úÖ Generowanie mowy za pomocƒÖ ElevenLabs
 */
const generateSpeech = async (text, fileName) => {
    if (!elevenLabsApiKey) {
        console.error("üö® B≈ÇƒÖd: Brak klucza API ElevenLabs!");
        return null;
    }

    try {
        const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceID}`, {
            method: "POST",
            headers: {
                "Content-Type": "application/json",
                "xi-api-key": elevenLabsApiKey,
            },
            body: JSON.stringify({
                text: text,
                model_id: "eleven_multilingual_v2",
                voice_settings: {
                    stability: 0.5,
                    similarity_boost: 0.5,
                    style: 0.0,
                    use_speaker_boost: true
                }
            }),
        });

        if (!response.ok) {
            console.error(`‚ùå B≈ÇƒÖd API ElevenLabs: ${response.status} - ${response.statusText}`);
            const errorData = await response.json();
            console.error("üìù Szczeg√≥≈Çy b≈Çƒôdu:", errorData);
            return null;
        }

        const audioBuffer = await response.arrayBuffer();
        await fs.writeFile(fileName, Buffer.from(audioBuffer));
        console.log(`‚úÖ Plik audio zapisany: ${fileName}`);

        return fileName;
    } catch (error) {
        console.error("‚ùå B≈ÇƒÖd po≈ÇƒÖczenia z ElevenLabs API:", error);
        return null;
    }
};

/**
 * ‚úÖ Generowanie lip sync + sprawdzanie b≈Çƒôd√≥w
 */
const lipSyncMessage = async (message) => {
  console.log(`üîÑ Rozpoczynam konwersjƒô dla wiadomo≈õci: ${message}`);

  try {
    await execCommand(`ffmpeg -y -i audios/message_${message}.mp3 audios/message_${message}.wav`);
    console.log(`‚úÖ Konwersja do WAV zako≈Ñczona`);
  } catch (error) {
    console.error("‚ùå B≈ÇƒÖd w FFmpeg:", error);
    return null;
  }

  try {
    await execCommand(`/usr/local/bin/Rhubarb-Lip-Sync-1.13.0-Linux/rhubarb -f json -o audios/message_${message}.json audios/message_${message}.wav -r phonetic`);
    console.log(`‚úÖ Lip sync zako≈Ñczony`);
  } catch (error) {
    console.error("‚ùå B≈ÇƒÖd w Rhubarb Lip Sync:", error);
    return null;
  }

  return await readJsonTranscript(`audios/message_${message}.json`);
};

/**
 * ‚úÖ Endpoint do czatu
 */
app.post("/chat", async (req, res) => {
  const userMessage = req.body.message;
  if (!userMessage) {
    return res.status(400).json({ error: "Brak wiadomo≈õci w ≈ºƒÖdaniu." });
  }

  if (!elevenLabsApiKey || openai.apiKey === "-") {
    return res.status(500).json({ error: "Brak kluczy API OpenAI i ElevenLabs." });
  }

  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      max_completion_tokens: 1000,
      temperature: 0.7,
      response_format: { type: "json_object" },
      messages: [
        { role: "system", content: "You will always reply with a JSON array of up to 3 messages, where each message has text, facialExpression (smile, sad, angry, surprised, funnyFace, default), and animation (Talking_0, Talking_1, Talking_2, Crying, Laughing, Rumba, Idle, Terrified, Angry) properties." },
        { role: "user", content: userMessage },
      ],
    });

    let messages = JSON.parse(completion.choices[0].message.content);
    if (messages.messages) {
      messages = messages.messages;
    }

    for (let i = 0; i < messages.length; i++) {
      const message = messages[i];

      const fileName = `audios/message_${i}.mp3`;
      await generateSpeech(message.text, fileName);
      message.lipsync = await lipSyncMessage(i);
      message.audio = await audioFileToBase64(fileName);
    }

    res.send({ messages });

  } catch (error) {
    console.error("‚ùå B≈ÇƒÖd OpenAI:", error);
    res.status(500).json({ error: "B≈ÇƒÖd podczas generowania odpowiedzi OpenAI." });
  }
});

app.listen(PORT, () => {
  console.log(`Virtual Girlfriend listening on port ${PORT}`);
});


const audioFileToBase64 = async (file) => {
  try {
    const data = await fs.readFile(file);
    return data.toString("base64");
  } catch (error) {
    console.error(`‚ùå B≈ÇƒÖd odczytu pliku audio: ${file}`, error);
    return null;
  }
};
