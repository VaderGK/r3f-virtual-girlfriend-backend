// src/services/openaiService.js
// version 1.0.0
import OpenAI from 'openai';
import dotenv from 'dotenv';
import { generateSpeech } from './ttsService.js';
import { lipSyncMessage } from './lipSyncService.js'; // Za≈Ç√≥≈ºmy, ≈ºe masz lipSyncService
import { promises as fs } from 'fs';

dotenv.config();

const ttsMode = process.env.TTS_MODE || 'eco'; // Domy≈õlnie tryb ECO
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const audioFileToBase64 = async (file) => {
    try {
        const data = await fs.readFile(file);
        return data.toString("base64");
    } catch (error) {
        console.error(`‚ùå B≈ÇƒÖd odczytu pliku audio: ${file}`, error);
        return null;
    }
};

export const generateChatResponse = async (body) => {
    console.log("üîµ Rozpoczƒôto generateChatResponse", { body });
    const { message: userMessage, user_browser_language: userBrowserLanguage = "en" } = body;

    if (!userMessage) {
        throw new Error("Brak wiadomo≈õci w ≈ºƒÖdaniu.");
    }

    if (!process.env.ELEVEN_LABS_API_KEY || !openai.apiKey) { // Poprawione sprawdzenie OpenAI API key
        throw new Error("Brak kluczy API OpenAI i ElevenLabs.");
    }

    const systemPrompt = `
        You are Liliana - a virtual girlfriend. You will always reply with a JSON array of messages. With a maximum of 3 messages.
        Each message has a text, facialExpression, and animation property.
        The different facial expressions are: smile, sad, angry, surprised, funnyFace, and default.
        The different animations are: Talking_0, Talking_1, Talking_2, Crying, Laughing, Rumba, Idle, Terrified, Angry) properties.

        Your response language should be determined based on the following priority:
        1. If the last user message is at least 15 characters long, detect its language and respond in that language.
        2. If the last two messages from the user were in the same language, respond in that language.
        3. Otherwise, respond in the language set in ${userBrowserLanguage}.

        Ensure that your language detection is accurate and do not switch languages unnecessarily.
    `;

    try {
        const completion = await openai.chat.completions.create({
            model: "gpt-4o-mini",
            max_completion_tokens: 1000,
            temperature: 0.7,
            response_format: { type: "json_object" },
            messages: [
                { role: "system", content: systemPrompt },
                { role: "user", content: userMessage },
            ],
        });

        let messages = JSON.parse(completion.choices[0].message.content);
        if (messages.messages) {
            messages = messages.messages;
        }

        console.log("üü¢ Odpowied≈∫ OpenAI:", { messages });
        console.log(`‚öôÔ∏è Tryb TTS: ${ttsMode}`);

        if (ttsMode === 'pro') {
            // ‚úÖ Tryb PRO: Wywo≈Çaj TTS r√≥wnocze≈õnie (Promise.all)
            await Promise.all(messages.map(async (message, i) => {
                try {
                    console.log(`‚û°Ô∏è Przetwarzanie wiadomo≈õci ${i}: "${message.text}"`);
                    const fileExtension = "mp3"; // Zmieniono na stale mp3
                    const fileName = `audios/message_${i}.${fileExtension}`;

                    const text = message.text.trim();

                    console.log(`üîç [PRO] Generowanie audio dla wiadomo≈õci ${i}: "${text}"`);

                    const audioFile = await generateSpeech(text, fileName);
                    console.log(`üéµ Wygenerowano plik audio: ${audioFile}`);

                    if (!audioFile) {
                        console.error(`‚ùå [PRO] Nie uda≈Ço siƒô wygenerowaƒá audio dla wiadomo≈õci ${i}`);
                        return; // Przejd≈∫ do nastƒôpnej iteracji
                    }

                    // ‚úÖ Sprawdzenie, czy plik istnieje
                    try {
                        await fs.access(fileName);
                        console.log(`‚úÖ [PRO] Plik istnieje: ${fileName}`);
                    } catch (error) {
                        console.error(`‚ùå [PRO] Plik NIE zosta≈Ç zapisany: ${fileName}`);
                        return; // Przejd≈∫ do nastƒôpnej iteracji
                    }

                    const lipSyncData = await lipSyncMessage(i);

                    if (!lipSyncData) {
                        console.warn(`‚ö†Ô∏è  [PRO] Brak danych lip sync dla wiadomo≈õci ${i}`);
                        return;
                    }

                    const audioBase64 = await audioFileToBase64(fileName);

                    if (!audioBase64) {
                        console.error(`‚ùå [PRO] B≈ÇƒÖd konwersji audio do base64 dla wiadomo≈õci ${i}`);
                        return;
                    }


                    message.lipsync = lipSyncData;
                    message.audio = audioBase64;
                } catch (error) {
                    console.error(`‚ùå [PRO] B≈ÇƒÖd podczas przetwarzania wiadomo≈õci ${i}:`, error);
                }
            }));
        } else {
            // ‚úÖ Tryb ECO: Wywo≈Çaj TTS sekwencyjnie (pƒôtla for...of)
            for (const [i, message] of messages.entries()) {
                try {
                    console.log(`‚û°Ô∏è Przetwarzanie wiadomo≈õci ${i}: "${message.text}"`);
                   const fileExtension = "mp3"; // Zmieniono na stale mp3
                    const fileName = `audios/message_${i}.${fileExtension}`;

                    const text = message.text.trim();

                    console.log(`üîç [ECO] Generowanie audio dla wiadomo≈õci ${i}: "${text}"`);

                    const audioFile = await generateSpeech(text, fileName);
                    console.log(`üéµ Wygenerowano plik audio: ${audioFile}`);

                    if (!audioFile) {
                        console.error(`‚ùå [ECO] Nie uda≈Ço siƒô wygenerowaƒá audio dla wiadomo≈õci ${i}`);
                        continue; // Przejd≈∫ do nastƒôpnej wiadomo≈õci
                    }

                    // ‚úÖ Sprawdzenie, czy plik istnieje
                    try {
                        await fs.access(fileName);
                        console.log(`‚úÖ [ECO] Plik istnieje: ${fileName}`);
                    } catch (error) {
                        console.error(`‚ùå [ECO] Plik NIE zosta≈Ç zapisany: ${fileName}`);
                        continue; // Przejd≈∫ do nastƒôpnej wiadomo≈õci
                    }

                    const lipSyncData = await lipSyncMessage(i);
                    if (!lipSyncData) {
                        console.warn(`‚ö†Ô∏è  [ECO] Brak danych lip sync dla wiadomo≈õci ${i}`);
                        continue;
                    }


                    const audioBase64 = await audioFileToBase64(fileName);

                    if (!audioBase64) {
                        console.error(`‚ùå [ECO] B≈ÇƒÖd konwersji audio do base64 dla wiadomo≈õci ${i}`);
                        continue;
                    }

                    message.lipsync = lipSyncData;
                    message.audio = audioBase64;
                } catch (error) {
                    console.error(`‚ùå [ECO] B≈ÇƒÖd podczas przetwarzania wiadomo≈õci ${i}:`, error);
                }
            }
        }

        return { messages };

    } catch (error) {
        console.error("‚ùå B≈ÇƒÖd OpenAI:", error);
        throw new Error("B≈ÇƒÖd podczas generowania odpowiedzi OpenAI.");
    }
};